{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "version-mejorada.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQ26Cuy0SAu+vDI2Es2/5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fedefliguer/bot_twitter_UnaTapaComoHoy/blob/master/version_mejorada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IimxVVZlyNnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import date\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import urllib.request\n",
        "import random\n",
        "import os\n",
        "import tempfile\n",
        "from werkzeug.utils import secure_filename\n",
        "import numpy as np\n",
        "from math import log\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# Classes\n",
        "\n",
        "class NewsPaper(ABC): \n",
        "    @abstractmethod\n",
        "    def get_url(self,new_day,new_month,current_year): \n",
        "        pass\n",
        "\n",
        "class Clarin(NewsPaper): \n",
        "    def get_url(self,new_day,new_month,current_year): \n",
        "        clarin_lags = np.arange(2,74)\n",
        "        lags = get_normalized_lags(clarin_lags)\n",
        "        new_year = str(current_year - lags)\n",
        "        return \"http://tapas.clarin.com/tapa/\" + new_year + \"/\" + new_month + \"/\" + new_day + \"/\" + new_year + new_month + new_day + \"_thumb.jpg\"\n",
        "\n",
        "\n",
        "class Pagina_12(NewsPaper): \n",
        "    def get_url(self,new_day,new_month,current_year): \n",
        "        pagina_12_lags = np.arange(2,19)\n",
        "        lags = get_normalized_lags(pagina_12_lags)\n",
        "        new_year = current_year - lags\n",
        "        if new_year == 2016:\n",
        "          new_year = \"2015\"\n",
        "          lags = 5\n",
        "        if lags < 4:\n",
        "          new_year = str(new_year)  \n",
        "          url = \"https://www.pagina12.com.ar/edicion-impresa/\" + new_day + \"-\" + new_month + \"-\" + new_year\n",
        "          req = requests.get(url, allow_redirects=True)\n",
        "          soup = BeautifulSoup(req.text,  \"html.parser\")\n",
        "          url = soup.findAll('img',{\"class\":\"lazyload \"})\n",
        "          if len(url)>0:\n",
        "            url = url[0][\"data-src\"]\n",
        "          else:\n",
        "            url = 'BAD URL'\n",
        "        else:\n",
        "          new_year = str(new_year)  \n",
        "          url = \"https://www.pagina12.com.ar/diario/principal/diario/index-\" + new_year + \"-\" + new_month + \"-\" + new_day + \".html\"\n",
        "          req = requests.get(url, allow_redirects=True)\n",
        "          soup = BeautifulSoup(req.text,  \"html.parser\")\n",
        "          alt = \"Tapa de la fecha \" + new_day + \"-\" + new_month + \"-\" + new_year\n",
        "          url = soup.findAll('img',{\"alt\":alt})\n",
        "          if len(url)>0:\n",
        "            url = url[0][\"src\"]\n",
        "          else:\n",
        "            url = 'BAD URL'\n",
        "        return url\n",
        "\n",
        "class Ole(NewsPaper): \n",
        "    def get_url(self,new_day,new_month,current_year): \n",
        "        ole_lags = np.arange(2,14)\n",
        "        lags = get_normalized_lags(ole_lags)\n",
        "        new_year = str(current_year - lags)\n",
        "        url = \"https://tapas2.ole.com.ar/tapa/\" + new_year + \"/\" + new_month + \"/\" + new_day + \"/\" + \"OLE_\" + new_year + new_month + new_day + \"_03.jpg\"\n",
        "    \n",
        "# Functions\n",
        "\n",
        "def get_newspaper(index):\n",
        "    newspapers = {\n",
        "        0: Clarin   ,\n",
        "        1: Pagina_12    ,\n",
        "        2: Ole\n",
        "    }\n",
        "    return newspapers[index]\n",
        "\n",
        "def get_normalized_lags(all_lags):\n",
        "    probs = [1/log(y,10) for y in all_lags]\n",
        "    probs = np.square(probs)\n",
        "    probs = probs/sum(probs)\n",
        "    return np.random.choice(all_lags, 1, p=probs)[0] - 1\n",
        "    \n",
        "\n",
        "def search():\n",
        "    # Get todays date\n",
        "    today = date.today()\n",
        "\n",
        "    # Set current year\n",
        "    current_year = today.year\n",
        "\n",
        "    # Set new day\n",
        "    new_day = \"{0:0=2d}\".format(today.day)\n",
        "    \n",
        "    # Set new month\n",
        "    new_month = \"{0:0=2d}\".format(today.month)\n",
        "    \n",
        "    # Some stuff\n",
        "    array = np.random.choice(3, 1, p=[0.4, 0.4, 0.2])\n",
        "    my_newspaper = get_newspaper(array[0])()\n",
        "    url = my_newspaper.get_url(new_day,new_month,current_year)\n",
        "    #diario = array[0]\n",
        "    \n",
        "\n",
        "    print(url)\n",
        "    request = requests.get(url, stream=True)\n",
        "    if request.status_code == 200:\n",
        "        respuesta = 'La encontré :)'\n",
        "    else:\n",
        "        respuesta = 'No la encontré :('\n",
        "    return respuesta + \" - \" + url\n",
        "\n",
        "search()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}